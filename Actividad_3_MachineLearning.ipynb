{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 3: Entrenamiento de un modelo de Machine Learning (ML)\n",
        "\n",
        "El proceso de entrenamiento de un modelo de ML consiste en proporcionar datos de entrenamiento, de los cuales aprende un algoritmo de ML (es decir, el algoritmo de aprendizaje). El término modelo de ML se refiere al artefacto de modelo que se crea en el proceso de entrenamiento. Los datos de entrenamiento se obtienen a través del proceso de ETL generado, el cual, debe contener la variable objetivo o tartet y cada de una de las variables que ayudan al modelo a encontrar la respuesta/salida correcta. Una vez los datos son obtenidos, inicial el proceso de entrenamiento. En un proceso de entrenamiento podemos encontrar diferentes pasos que varian dependiendo de la complejidad del problema, que son: preprocesamiento de datos, definir arquitectura del modelo, entrenar y evaluar el desempeño.\n",
        "\n",
        "En la presente actividad entrenaremos un modelo de ML para identificar si un tipo de cáncer de mama puede ser **Maligno** o **Benigno**, la cual, vendría a ser nuestra variable objetivo o target. En el dataset, haremos uso de las siguientes características.\n",
        "\n",
        "* radius: media de las distancias del centro a los puntos del perímetro\n",
        "* texture: desviación estándar de los valores de la escala de grises\n",
        "* perimeter\n",
        "* area\n",
        "* smoothness: variación local en longitudes de radio\n",
        "* compactness:(perimeter^2 / area - 1.0)\n",
        "* concavity: gravedad de las porciones cóncavas del contorno\n",
        "* concave points: número de porciones cóncavas del contorno\n",
        "* symmetry\n",
        "* fractal dimension: (aproximación a la línea de costa\" - 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "GCU1CNRa9mRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports \n",
        "\n",
        "Librerias que se necesitan para el desarrollo de la actividad"
      ],
      "metadata": {
        "id": "c-shzmd4AmIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "FF1EG-nJAqDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurando pandas para visualización de 100 columnas"
      ],
      "metadata": {
        "id": "bXkGsATgO70J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = 100"
      ],
      "metadata": {
        "id": "eT5054F4PD0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura del dataset"
      ],
      "metadata": {
        "id": "DGsQJqk2PWu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://raw.githubusercontent.com/eyberthrojas/Actividad_3_ML/main/is_cancer.csv'\n",
        "data = pd.read_csv(path, on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "KL6aWwQQPccY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensión del dataset\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ov1uhsoBcmS",
        "outputId": "28126931-37cc-4d4f-cfc3-cfb8356dfab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('is_cancer.csv', index=False)"
      ],
      "metadata": {
        "id": "3_CHDWXtaOsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeros 5 registros del dataset\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "5uZB7XRkBBPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspeccionando la variable objetivo\n",
        "data.diagnosis.value_counts()"
      ],
      "metadata": {
        "id": "cTP_llriBGTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando si hay presentes valores NULLs en el dataset\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "O0cvPfDjBnAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "_**Generalmente, los IDs que identifican registros en un dataset no aportan información significativa al entrenamiento de un modelo de ML. Al igual que los valores NULL**_"
      ],
      "metadata": {
        "id": "D2jXttdLCtMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['Unnamed: 32', 'id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "LRD5k904CegF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "Qka2uUOfK2tO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_**Como se mencionó al inicio del notebook. Para esta actividad, solo utilizaremos algunas features del dataset completo**_"
      ],
      "metadata": {
        "id": "aSXN7gYBa3bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_finales = [\n",
        "    \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\",\n",
        "    \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \n",
        "    \"fractal_dimension_mean\", \"diagnosis\"\n",
        "]"
      ],
      "metadata": {
        "id": "3IA3N4UuZvHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionamos solo las features de interés del dataset completo\n",
        "dataset_final = data[features_finales].copy(deep=True)"
      ],
      "metadata": {
        "id": "ZLEMJS7UZvKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver tipos de datos de nuestro conjunto de datos\n",
        "dataset_final.dtypes"
      ],
      "metadata": {
        "id": "WTxorrfaZvM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar que todas las features son de tipo númerico. En un proceso de entrenamiento de un modelo de ML nos podemos encontrar con otros tipos de datos, como los categóricos. Para efectos de creación del proceso de entrenamiento que nos ofrece Sklearn, crearemos una variable categórica. **Nota:** la menera de crear la variable categórica se realiza de aleatoria, sin embargo, en ciencia de datos existe un proceso llamado **Feature Engineering**, en donde se detallan otra maneras de realizrlo"
      ],
      "metadata": {
        "id": "fkITuOoKcSyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable categórica creada a partir de la feature fractal_dimension_mean. \n",
        "dataset_final[\"calc_fractal_dimension_mean\"] = np.where(\n",
        "    1, dataset_final[\"fractal_dimension_mean\"] < 0.055, \n",
        "    0\n",
        ")"
      ],
      "metadata": {
        "id": "FSyMCjxPc5Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos la variable númerica que usamos para crear la variable categórica\n",
        "dataset_final.drop(['fractal_dimension_mean'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "L5jrV934d3vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline de Sklearn para el entrenamiento de un modelo de ML\n",
        "\n",
        "[Sklearn](https://scikit-learn.org/stable/) ofrece una serie de pasos en los cuales podemos definir la arquitectura de nuestro modelo. En estos pasos, podemos definir el preprocesamiento de nuestras variables númericas y categóricas, realizar un feature unión y especificar el algoritmo de ML a usar\n"
      ],
      "metadata": {
        "id": "4oh2wl9BfUtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase que realiza el fit y transform a una variable\n",
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Select only specified columns.\"\"\"\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return X[self.columns]"
      ],
      "metadata": {
        "id": "qmbH7TCwgmCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definicíon de pipeline variables númericas"
      ],
      "metadata": {
        "id": "gf1t1iUyfUwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features numéricas\n",
        "numerical = [\n",
        "    \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\",\n",
        "    \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\"\n",
        "]"
      ],
      "metadata": {
        "id": "w2yUuN1fgDAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ColumnSelector: selecciona las columnas númericas del dataset de entrenamiento\n",
        "# SimpleImputer: los valores faltantes los completa con la mediana de todos los valores de la feature\n",
        "num_pipe = Pipeline([\n",
        "    ('selector', ColumnSelector(numerical)),\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "])"
      ],
      "metadata": {
        "id": "m6j4lcW2f-yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definicíon de pipeline variables categóricas"
      ],
      "metadata": {
        "id": "_IeiElmIhivu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features categóricas\n",
        "categorical = [\"calc_fractal_dimension_mean\"]"
      ],
      "metadata": {
        "id": "ecqv0ZihhlYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ColumnSelector: selecciona las columnas categóricas del dataset de entrenamiento\n",
        "# SimpleImputer: los valores faltantes los completa con un valor fijo\n",
        "# OneHotEncoder: codificación de variables categóricas\n",
        "cat_pipe = Pipeline([\n",
        "    ('selector', ColumnSelector(categorical)),\n",
        "    ('imputer', SimpleImputer(strategy='constant')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "])"
      ],
      "metadata": {
        "id": "jAoMZVvUf-09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature union de todas las features categóricas y numéricas\n",
        "preprocessor = FeatureUnion([\n",
        "    ('cat', cat_pipe),\n",
        "    ('num', num_pipe)\n",
        "])"
      ],
      "metadata": {
        "id": "MXjnhQxgiRlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline final del proceso de entrenamiento\n",
        "pipe = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', svm.SVC())\n",
        "])"
      ],
      "metadata": {
        "id": "n5_ey64Vf-3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se elimina la variable target de los datos que contienen las features \n",
        "X = dataset_final.drop(['diagnosis'], axis = 1)"
      ],
      "metadata": {
        "id": "2ViNw4x5isv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera en una variable separada el target del problema, en este caso \"Diagnosis\"\n",
        "y = dataset_final['diagnosis']"
      ],
      "metadata": {
        "id": "WW5R_AWeiy7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# De todo el conjunto de datos se toman crean datos de train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
        "print(\"Size of training set:\", X_train.shape)\n",
        "print(\"Size of test set:\", X_test.shape)"
      ],
      "metadata": {
        "id": "gvogSi7-iy99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model = pipe.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "9xcTCezrf-6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción sobre los datos de test\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "A3DGq5Jjf-9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validación performance del modelo\n",
        "\n",
        "Evaluamos el desempeño del modelo haciendo uso de la librería [Classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)  que otorga Sklearn. En esta tabla podemos encontrar diferentes métricas, en donde cada una se utiliza dependiendo del problema a resolver y como afecta una mala predicción por parte del modelo. Para esta actividad, vamos a usar el **Accuracy**, la cual, lo que nos muestra es el porcentaje de casos que el modelo ha acertado, en esta actividad, obtenemos un accuracy del **0.88**"
      ],
      "metadata": {
        "id": "9swYqzuOjovn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "id": "ek573bHDjiEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste de Hiperparámetros del modelo\n",
        "\n",
        "Los hiperparámetros se definen como los parámetros definidos explícitamente por el usuario para controlar el proceso de aprendizaje. Cada algortimo de aprendizaje automático contiene hiperparámetros específicos que se seleccionan y optimizan durante el proceso de entrenamiento con el objetivo de mejorar el desempeño del modelo.\n",
        "\n",
        "Para la actividad, utilizaremos ***GridSearchCV***, el cual, es una librería se [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) que realiza una búsqueda exhaustiva sobre valores de parámetros específicos para un estimador, en este caso, para el [Support Vector Machine (SVM)](https://scikit-learn.org/stable/modules/svm.html)\n"
      ],
      "metadata": {
        "id": "ohDvyFqhHqrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un rango de búsqueda de mejores hiperparámetros\n",
        "parameters = [\n",
        "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
        "]"
      ],
      "metadata": {
        "id": "6F4Rclt9JtMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Búsqueda de mejores hiperaparámetros. Esta busqueda se realiza utilizando los datos de entrenamiento\n",
        "svc = svm.SVC()\n",
        "clf = GridSearchCV(svc, parameters)\n",
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "q3xgLSZqJtPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejores hiperparametros encontrados por GridSearch\n",
        "clf.best_params_"
      ],
      "metadata": {
        "id": "iGzKw_LFneFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar el pipeline con los mejores hiperparametros\n",
        "pipe = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', svm.SVC(C=10, kernel='linear'))\n",
        "])"
      ],
      "metadata": {
        "id": "4fCiuDw5neIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar nuevamente\n",
        "model = pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Jn-wQ09-kAxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir nuevamente sobre los datos de test\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "tbCHNrmoGMWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "id": "YYca2OBzozc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que el accuracy aumenta del 0.88 al 0.91. Con esto, podemos notar que la optimización de los hiperparámetros del modelo es un paso que ayuda al modelo a tener un mejor desempeño en diferentes tipos de tareas, para esta actividad, una tarea centrada en la clasificación de dos tipos de cancer de mama"
      ],
      "metadata": {
        "id": "VHoR5dQcsSiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOGVnjvAb0uV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}